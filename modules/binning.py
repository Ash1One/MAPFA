#!/usr/bin/env python
# -*- coding: utf-8 -*-

import logging
import os
import pandas as pd
import subprocess
import shutil
from pathlib import Path

from .utils import fileExists, makesurePathExists
from modules.scripts import extract_fasta_bins


def metabat2bin(align_outdir, assembly_file, metabat_minlength, threads, tbam_files):
    '''return the path of bin outdir
    '''

    logger = logging.getLogger('mapfa')
    logger.info("making coverage file for metabat2...")
    depth_path = os.path.join(align_outdir, 'metabat2_depth.txt')
    if fileExists(depth_path):
        os.remove(depth_path)
    cmd_mk_cov = ' '.join(('jgi_summarize_bam_contig_depths', ' --outputDepth',
                           depth_path) + tbam_files)
    logger.info("Command: %s", cmd_mk_cov)
    try:
        subprocess.run(cmd_mk_cov, shell=True, check=True)
    except Exception:
        logger.critical(
            "Something wrong when making converage file for metabat2.", exc_info=True)
        raise
    else:
        logger.info("Start binning with metabat2...")
        metabat2_bin_out = os.path.join(
            os.path.dirname(align_outdir), 'metabat2_bins', 'bin')
        cmd_metabat2 = ' '.join(['metabat2', '-t', str(threads), '-i', assembly_file, '-a', os.path.join(
            align_outdir, 'metabat2_depth.txt'), '-o', metabat2_bin_out, '-m', str(metabat_minlength), '--unbinned'])
        logger.info("Command: %s", cmd_metabat2)
        try:
            subprocess.run(cmd_metabat2, shell=True, check=True)
        except Exception:
            logger.critical(
                "Something wrong when binning with metabat2...", exc_info=True)
            raise
        else:
            metabat2_bin_outdir = os.path.join(
                os.path.dirname(align_outdir), 'metabat2_bins')
            num_bins = len(list(Path(metabat2_bin_outdir).glob('bin*.fa')))
            logger.info(
                "Success! Total %d bins were generated by metabat2.", num_bins)
            return metabat2_bin_outdir


def maxbin2bin(align_outdir, assembly_file, minlength, threads, tbam_files):
    '''return the path of bin outdir
    '''

    logger = logging.getLogger('mapfa')
    logger.info("making coverage file for maxbin2...")
    depth_path = os.path.join(align_outdir, 'maxbin2_depth.txt')
    if fileExists(depth_path):
        os.remove(depth_path)
    cmd_mk_cov = ' '.join(('jgi_summarize_bam_contig_depths', ' --outputDepth', depth_path + '--noIntraDepthVariance') + tbam_files)
    try:
        subprocess.run(cmd_mk_cov, shell=True, check=True)
    except Exception:
        logger.critical(
            "Something wrong when making converage file for maxbin2.", exc_info=True)
        raise
    else:
        # cut maxbin2_depth to depth files for different samples.
        depth = pd.read_table(depth_path)
        maxbin2_abundant = []
        for col in depth.columns[3:]:
            abundant_file = 'maxbin2_'+col.replace('bam', 'txt')
            depth.loc[:, ['contigName', col]].to_csv(
                abundant_file, sep='\t', header=False, index=False)
            maxbin2_abundant.append(abundant_file)

        with open(os.path.join(align_outdir, 'maxbin2_abundant.txt'), 'w') as f:
            for file in maxbin2_abundant:
                f.write(os.path.abspath(file))
                f.write('\n')

    # run_MaxBin.pl
    run_Maxbin = subprocess.run('run_MaxBin.pl', shell=True, check=True, stdout=subprocess.PIPE)
    if not run_Maxbin:
        logger.critical("Something wrong when running run_Maxbin.pl, please check if perl was setted correctly.")
        return False
    logger.info("Start binning with maxbin2...")
    maxbin2_out = os.path.join(align_outdir, 'maxbin2_out', 'bin')
    cmd_maxbin2 = ' '.join(['run_MaxBin.pl', '-contig', assembly_file, '-out', maxbin2_out, '-abund_list', os.path.join(align_outdir, 'maxbin2_abundant.txt'), '-min_contig_length', str(minlength), '-thread', str(threads)])
    try:
        subprocess.run(cmd_maxbin2, shell=True, check=True)
    except Exception:
        logger.critical("Something wrong when binning with maxbin2...", exc_info=True)
        raise

    maxbin2_bin_dir = os.path.join(os.path.dirname(align_outdir), 'maxbin2_bins')
    makesurePathExists(maxbin2_bin_dir)
    bin_num = 0
    for bin_path in list(Path(align_outdir).joinpath('maxbin2_out').glob('bin*.fasta')):
        shutil.copy(str(bin_path), os.path.join(maxbin2_bin_dir, 'bin.'+str(bin_num)+'.fasta'))
        bin_num += 1
    logger.info("Success! Total %d bins were generated by maxbin2.", bin_num)
    return maxbin2_bin_dir


def groopm2bin(align_outdir, assembly_file, threads, tbam_files):
    logger = logging.getLogger('mapfa')
    groopm_help = subprocess.run('groopm2 -h', shell=True, check=True, stdout=subprocess.PIPE)
    if not groopm_help:
        logger.error("Something wrong when running groopm2, please check if groopm2 was installed correctly.", exc_info=True)
        return False
    logger.info("Start binning with groopm2...")
    groopm2_outdir = os.path.join(align_outdir, 'groopm2_out')
    makesurePathExists(groopm2_outdir)
    groopm2_db = os.path.join(groopm2_outdir, 'groopm2_db')
    groopm2_bin_dir = os.path.join(os.path.dirname(align_outdir), 'groopm2_bins')

    cmd_parse = ' '.join(('groopm2', 'parse', '-t', str(threads), groopm2_db, assembly_file) + tbam_files)
    cmd_core = ' '.join(['groopm2', 'core', groopm2_db])
    cmd_extract = ' '.join(['groopm2', 'extract', '-o', groopm2_bin_dir, '-t', str(threads), groopm2_db, assembly_file])
    try:
        # Parse raw data and save
        subprocess.run(cmd_parse, shell=True, check=True)
    except Exception:
        logger.error("Something wrong when running groopm2 parse module!", exc_info=True)
        raise
    else:
        try:
            # Load saved data and make bin cores
            subprocess.run(cmd_core, shell=True, check=True)
        except Exception:
            logger.error("Something wrong when running groopm2 core module!", exc_info=True)
            raise
        else:
            try:
                # Extract contigs or reads based on bin affiliations
                subprocess.run(cmd_extract, shell=True, check=True)
            except Exception:
                logger.error("Something wrong when running groopm2 extract module!", exc_info=True)
                raise
    num_bins = len(list(Path(groopm2_bin_dir).glob('*bin*.fa')))
    logger.info("Success! Total %d bins were generated by groopm2.", num_bins)
    return groopm2_bin_dir


def concoct2bin(align_outdir, assembly_file, minlength, threads, tbam_files):
    logger = logging.getLogger('mapfa')
    contig_bed = os.path.join(align_outdir, 'concoct_contig_10k.bed')
    contig_10k = os.path.join(align_outdir, 'concoct_contig_10k.fa')
    coverage_table = os.path.join(align_outdir, 'coverage_table.tsv')
    concoct_out = os.path.join(align_outdir, 'concoct_out')
    clustering_merged = os.path.join(concoct_out, 'clustering_merged.csv')
    # cut contigs into samller parts
    logger.info("CONCOCT -- cut contigs into samller parts")
    subprocess.run(' '.join(['cut_up_fasta.py', assembly_file, '-c', '10000', '-o', '0', '--merge_last', '-b', contig_bed, '>', contig_10k]), shell=True, check=True)
    if not fileExists(contig_10k):
        logger.error("Something went wrong when running cut_up_fasta.py (CONCOCT).")
        return False
    
    # generate the coverage table
    logger.info("CONCOCT -- generate the coverage table")
    subprocess.run(' '.join(('concoct_coverage_table.py', contig_10k) + tbam_files + ('>', coverage_table)), shell=True, check=True)
    if not fileExists(coverage_table):
        logger.error("Something went wrong when generating coverage table by CONCOCT.")
        return False

    # Run CONCOCT
    logger.info("Run concoct...")
    subprocess.run(' '.join(['concoct', '-l', str(minlength), '-t', str(threads), '--composition_file', contig_10k, '--coverage_file', coverage_table, '-b', concoct_out]), shell=True, check=True)
    if not fileExists(os.path.join(concoct_out, 'clustering_gt'+str(minlength)+'.csv')):
        logger.error("Something went wrong when running CONCOCT")
        return False

    # Merge subcontig clustering into original contig clustering
    logger.info("CONCOCT -- Merge subcontig clustering into original contig clustering")
    subprocess.run(' '.join(['merge_cutup_clustering.py', os.path.join(concoct_out, 'clustering_gt'+str(minlength)+'.csv'), '>', clustering_merged]), shell=True, check=True)

    # Extract bins as individual FASTA
    concoct_bin_dir = os.path.join(os.path.dirname(align_outdir), 'concoct_bins')
    logger.info("CONCOCT -- extract bins as individual FASTA")
    subprocess.run(' '.join(['extract_fasta_bins.py', assembly_file, clustering_merged, '--output_path', concoct_bin_dir]), shell=True, check=True)

    num_bins = len(list(Path(concoct_bin_dir).glob('*.fa')))
    logger.info("Success! Total %d bins were generated by concoct.", num_bins)
    return concoct_bin_dir